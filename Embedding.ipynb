{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3849173",
   "metadata": {},
   "source": [
    "# Enhanced Embeddings with Top 5 Models\n",
    "\n",
    "We implement separate embeddings with weights for the **`title`**, **`plot`** and **`genres`** fields using the 3 different sentence transformer models, time the embedding processes, and save each to separate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66eb9952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danil\\anaconda3\\envs\\dls\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict, Union\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73dad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_dataset.csv')\n",
    "df['genres_str'] = df['genres'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b4e5f3",
   "metadata": {},
   "source": [
    "## Models Selection\n",
    "\n",
    "3 models were chosen based on the [Sentence-Transformers leaderboard](https://www.sbert.net/docs/pretrained_models.html):\n",
    "\n",
    "1. **all-mpnet-base-v2**: Highest general-purpose accuracy (12-layer, 768-hidden-dimension)\n",
    "4. **all-MiniLM-L12-v2**: Balance of speed and performance (12-layer, 384-hidden-dimension)\n",
    "5. **multi-qa-distilbert-cos-v1**: Fastest model with QA optimization, has been specifically trained for Semantic Search (6-layer, 768-hidden-dimension)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17fe26af",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = {'title': 0.15, 'plot': 0.6, 'genres': 0.25}\n",
    "\n",
    "MODELS = {\n",
    "    'all-mpnet-base-v2',\n",
    "    'all-MiniLM-L12-v2',\n",
    "    'multi-qa-distilbert-cos-v1'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4de42",
   "metadata": {},
   "source": [
    "## Embedding Generation\n",
    "\n",
    "We'll generate embeddings for each model, time the process, and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa08b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "\n",
    "os.makedirs('embeddings', exist_ok=True)\n",
    "\n",
    "def generate_embeddings(model_name, texts):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = model.encode(texts, convert_to_tensor=True)\n",
    "    embeddings = [emb.cpu() for emb in embeddings]\n",
    "    return embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "# Dictionary to store timing results\n",
    "timing_results = {}\n",
    "\n",
    "for model_name in MODELS:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Generate all embeddings\n",
    "    title_start = time.time()\n",
    "    title_emb = generate_embeddings(model_name, df['title'].tolist())\n",
    "    title_time = time.time() - title_start\n",
    "    \n",
    "    plot_start = time.time()\n",
    "    plot_emb = generate_embeddings(model_name, df['plot'].tolist())\n",
    "    plot_time = time.time() - plot_start\n",
    "    \n",
    "    genres_start = time.time()\n",
    "    genres_emb = generate_embeddings(model_name, df['genres_str'].tolist())\n",
    "    genres_time = time.time() - genres_start\n",
    "    \n",
    "    # Combine with stable weights\n",
    "    combined_emb = (\n",
    "        WEIGHTS['title'] * title_emb +\n",
    "        WEIGHTS['plot'] * plot_emb + \n",
    "        WEIGHTS['genres'] * genres_emb\n",
    "    )\n",
    "    \n",
    "    \n",
    "    filename = f\"embeddings/embeddings_{model_name.replace('-', '_')}.npy\"\n",
    "    np.save(filename, combined_emb)\n",
    "    \n",
    "    # Calculate total time\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # Store timing results\n",
    "    timing_results[model_name] = {\n",
    "        'title_embedding_time': title_time,\n",
    "        'plot_embedding_time': plot_time,\n",
    "        'genres_embedding_time': genres_time,\n",
    "        'total_time': total_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67bc388a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation times saved to 'embedding_generation_times.txt'\n"
     ]
    }
   ],
   "source": [
    "with open('embedding_generation_times.txt', 'a') as f:\n",
    "    for model_name, times in timing_results.items():\n",
    "        f.write(f\"Model: {model_name}\\n\")\n",
    "        f.write(f\"  Title embeddings: {times['title_embedding_time']:.2f} seconds\\n\")\n",
    "        f.write(f\"  Plot embeddings: {times['plot_embedding_time']:.2f} seconds\\n\")\n",
    "        f.write(f\"  Genres embeddings: {times['genres_embedding_time']:.2f} seconds\\n\")\n",
    "        f.write(f\"  Total time: {times['total_time']:.2f} seconds\\n\\n\")\n",
    "\n",
    "print(\"Embedding generation times saved to 'embedding_generation_times.txt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
