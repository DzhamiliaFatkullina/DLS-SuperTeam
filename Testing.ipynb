{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df03207e",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc6e95f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.modeling_utils because of the following error (look up to see its traceback):\nmodule 'torch' has no attribute 'version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1967\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:63\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflash_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flash_attention_forward\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flex_attention_forward\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdpa_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sdpa_attention_forward\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\integrations\\flex_attention.py:39\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_flex_attn_available():\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BlockMask, flex_attention\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     41\u001b[0m         create_block_mask \u001b[38;5;28;01mas\u001b[39;00m create_block_causal_mask_flex,\n\u001b[0;32m     42\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\attention\\flex_attention.py:16\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_trace_wrapped_higher_order_op\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformGetItemToIndex\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flex_attention \u001b[38;5;28;01mas\u001b[39;00m flex_attention_hop\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:33\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorifyScalarRestartAnalysis\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tracing, TracingContext\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_dynamo\\exc.py:11\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m counters\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_dynamo\\utils.py:65\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_functorch\\config.py:66\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# When AOTAutograd regenerates aliased graph outputs,\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# attempt to use functionalization's view-replay logic\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# before falling back to the autograd engine's view replay or as_strided.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# once XLA pin update works,\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# or default config to true and fix relevant bugs\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_fbcode\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# View replay is currently not compatible with AOTAutogradCache, since\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# FunctionalTensors are not serializable. We'll need to make them\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# serializable before enabling warm cache with this config turned on.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_inductor\\__init__.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Tuple, TYPE_CHECKING, Union\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_inductor\\config.py:404\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;66;03m# Disabled by default on ROCm, opt-in if model utilises NHWC convolutions\u001b[39;00m\n\u001b[1;32m--> 404\u001b[0m layout_opt_default \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241m.\u001b[39mhip \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    405\u001b[0m layout_optimization \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    406\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCHINDUCTOR_LAYOUT_OPTIMIZATION\u001b[39m\u001b[38;5;124m\"\u001b[39m, layout_opt_default) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    407\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py:2681\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m   2679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m-> 2681\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'version'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\__init__.py:14\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[0;32m     11\u001b[0m     export_optimized_onnx_model,\n\u001b[0;32m     12\u001b[0m     export_static_quantized_openvino_model,\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     CrossEncoder,\n\u001b[0;32m     16\u001b[0m     CrossEncoderModelCardData,\n\u001b[0;32m     17\u001b[0m     CrossEncoderTrainer,\n\u001b[0;32m     18\u001b[0m     CrossEncoderTrainingArguments,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trange\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     AutoConfig,\n\u001b[0;32m     21\u001b[0m     AutoModelForSequenceClassification,\n\u001b[0;32m     22\u001b[0m     AutoTokenizer,\n\u001b[0;32m     23\u001b[0m     PretrainedConfig,\n\u001b[0;32m     24\u001b[0m     PreTrainedModel,\n\u001b[0;32m     25\u001b[0m     PreTrainedTokenizer,\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1955\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1953\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32mc:\\Users\\Джамиля\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1969\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1970\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1972\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_utils because of the following error (look up to see its traceback):\nmodule 'torch' has no attribute 'version'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d9429",
   "metadata": {},
   "source": [
    "### Ranking of recommendation lists\n",
    "\n",
    "**`MetricsCalculator`** class is designed for evaluating our recommendation system's results with **Precision@k**, **Recall@k**, **MAP**, and **NDCG** metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b6540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCalculator:\n",
    "    @staticmethod\n",
    "    def precision_at_k(relevant_items: List[int], recommended_items: List[int], k: int) -> float:\n",
    "        top_k = recommended_items[:k]\n",
    "        relevant_in_top_k = len(set(top_k) & set(relevant_items))\n",
    "        return relevant_in_top_k / k if k > 0 else 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def recall_at_k(relevant_items: List[int], recommended_items: List[int], k: int) -> float:\n",
    "        top_k = recommended_items[:k]\n",
    "        relevant_in_top_k = len(set(top_k) & set(relevant_items))\n",
    "        return relevant_in_top_k / len(relevant_items) if relevant_items else 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def average_precision(relevant_items: List[int], recommended_items: List[int]) -> float:\n",
    "        ap = 0.0\n",
    "        num_relevant = len(relevant_items)\n",
    "        relevant_positions = [i+1 for i, item in enumerate(recommended_items) if item in relevant_items]\n",
    "        \n",
    "        for i, pos in enumerate(relevant_positions):\n",
    "            ap += (i+1) / pos\n",
    "        \n",
    "        return ap / num_relevant if num_relevant > 0 else 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def mean_average_precision(relevant_items_list: List[List[int]], recommended_items_list: List[List[int]]) -> float:\n",
    "        ap_scores = [\n",
    "            MetricsCalculator.average_precision(relevant, recommended)\n",
    "            for relevant, recommended in zip(relevant_items_list, recommended_items_list)\n",
    "        ]\n",
    "        return np.mean(ap_scores) if ap_scores else 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def ndcg_at_k(relevant_items: List[int], recommended_items: List[int], k: int, relevance_scores: Dict[int, float] = None) -> float:\n",
    "        top_k = recommended_items[:k]\n",
    "        if relevance_scores is None:\n",
    "            relevance_scores = {item: 1.0 for item in relevant_items}\n",
    "        \n",
    "        dcg = sum(\n",
    "            (relevance_scores.get(item, 0) / np.log2(i + 2) \n",
    "            for i, item in enumerate(top_k))\n",
    "        )\n",
    "        \n",
    "        ideal_relevance = sorted([relevance_scores.get(item, 0) for item in relevant_items], reverse=True)[:k]\n",
    "        idcg = sum(rel / np.log2(i + 2) for i, rel in enumerate(ideal_relevance))\n",
    "        \n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_all_metrics(\n",
    "        relevant_items_list: List[List[int]],\n",
    "        recommended_items_list: List[List[int]],\n",
    "        k_values: List[int] = [1, 3, 5, 10],\n",
    "        relevance_scores_list: List[Dict[int, float]] = None\n",
    "    ) -> Dict[str, Union[float, Dict[int, float]]]:\n",
    "        results = {\n",
    "            'MAP': MetricsCalculator.mean_average_precision(relevant_items_list, recommended_items_list),\n",
    "            'Precision@k': {},\n",
    "            'Recall@k': {},\n",
    "            'NDCG@k': {}\n",
    "        }\n",
    "        \n",
    "        for k in k_values:\n",
    "            results['Precision@k'][k] = np.mean([\n",
    "                MetricsCalculator.precision_at_k(relevant, recommended, k)\n",
    "                for relevant, recommended in zip(relevant_items_list, recommended_items_list)\n",
    "            ])\n",
    "            \n",
    "            results['Recall@k'][k] = np.mean([\n",
    "                MetricsCalculator.recall_at_k(relevant, recommended, k)\n",
    "                for relevant, recommended in zip(relevant_items_list, recommended_items_list)\n",
    "            ])\n",
    "            \n",
    "            if relevance_scores_list:\n",
    "                results['NDCG@k'][k] = np.mean([\n",
    "                    MetricsCalculator.ndcg_at_k(relevant, recommended, k, rel_scores)\n",
    "                    for relevant, recommended, rel_scores in zip(relevant_items_list, recommended_items_list, relevance_scores_list)\n",
    "                ])\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cabed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from annoy import AnnoyIndex\n",
    "import faiss\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "\n",
    "class SearchEvaluator:\n",
    "    \"\"\"Class to evaluate different search approaches\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path: str):\n",
    "        # Load validation data\n",
    "        with open(data_path, 'r') as f:\n",
    "            self.validation_data = json.load(f)\n",
    "        \n",
    "        # Create movie title to index mapping\n",
    "        self.movie_titles = list({movie for item in self.validation_data for movie in item['relevant_movies']})\n",
    "        self.title_to_idx = {title: idx for idx, title in enumerate(self.movie_titles)}\n",
    "        \n",
    "        # Prepare queries and relevant items\n",
    "        self.queries = [item['query'] for item in self.validation_data]\n",
    "        self.relevant_items_list = [\n",
    "            [self.title_to_idx[title] for title in item['relevant_movies'] if title in self.title_to_idx]\n",
    "            for item in self.validation_data\n",
    "        ]\n",
    "        \n",
    "        # Load all embeddings\n",
    "        self.embeddings = {}\n",
    "        self.models = {\n",
    "            'all_mpnet_base_v2',\n",
    "            'all_MiniLM_L12_v2',\n",
    "            'multi_qa_distilbert_cos_v1'\n",
    "        }\n",
    "        \n",
    "        for model in self.models:\n",
    "            emb_path = f\"embeddings/embeddings_{model.replace('-', '_')}.npy\"\n",
    "            self.embeddings[model] = np.load(emb_path)\n",
    "        \n",
    "        # Initialize BM25 (separate from embeddings)\n",
    "        tokenized_titles = [title.lower().split() for title in self.movie_titles]\n",
    "        self.bm25 = BM25Okapi(tokenized_titles)\n",
    "    \n",
    "    def bm25_search(self, query: str, top_k: int = 5) -> List[int]:\n",
    "        tokenized_query = query.lower().split()\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        return np.argsort(scores)[-top_k:][::-1].tolist()\n",
    "    \n",
    "    def cosine_search(self, query: str, model_name: str, top_k: int = 5) -> List[int]:\n",
    "        model = SentenceTransformer(model_name.replace(\"_\", \"-\"))\n",
    "        query_emb = model.encode([query])\n",
    "        emb_matrix = self.embeddings[model_name]\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        query_emb = query_emb / np.linalg.norm(query_emb)\n",
    "        emb_matrix = emb_matrix / np.linalg.norm(emb_matrix, axis=1, keepdims=True)\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        scores = np.dot(emb_matrix, query_emb.T).flatten()\n",
    "        return np.argsort(scores)[-top_k:][::-1].tolist()\n",
    "    \n",
    "    def faiss_flat_search(self, query: str, model_name: str, top_k: int = 5) -> List[int]:\n",
    "        model = SentenceTransformer(model_name.replace(\"_\", \"-\"))\n",
    "        query_emb = model.encode([query])\n",
    "        emb_matrix = self.embeddings[model_name]\n",
    "        \n",
    "        # Build FAISS index\n",
    "        dimension = emb_matrix.shape[1]\n",
    "        index = faiss.IndexFlatIP(dimension)\n",
    "        index.add(emb_matrix.astype('float32')) # for cuda\n",
    "        \n",
    "        # Search\n",
    "        distances, indices = index.search(query_emb.astype('float32'), top_k)\n",
    "        return indices[0].tolist()\n",
    "    \n",
    "    def faiss_hnsw_search(self, query: str, model_name: str, top_k: int = 5) -> List[int]:\n",
    "        model = SentenceTransformer(model_name.replace(\"_\", \"-\"))\n",
    "        query_emb = model.encode([query])\n",
    "        emb_matrix = self.embeddings[model_name]\n",
    "        \n",
    "        # Build HNSW index\n",
    "        dimension = emb_matrix.shape[1]\n",
    "        index = faiss.IndexHNSWFlat(dimension, 32)  # 32 is HNSW parameter\n",
    "        index.add(emb_matrix.astype('float32')) # float32 for cuda\n",
    "        \n",
    "        # Search\n",
    "        distances, indices = index.search(query_emb.astype('float32'), top_k)\n",
    "        return indices[0].tolist()\n",
    "    \n",
    "    def annoy_search(self, query: str, model_name: str, top_k: int = 5) -> List[int]:\n",
    "        model = SentenceTransformer(model_name.replace(\"_\", \"-\"))\n",
    "        query_emb = model.encode([query])\n",
    "        emb_matrix = self.embeddings[model_name]\n",
    "        \n",
    "        # Build Annoy index\n",
    "        dimension = emb_matrix.shape[1]\n",
    "        annoy_index = AnnoyIndex(dimension, 'angular')\n",
    "        for i, emb in enumerate(emb_matrix):\n",
    "            annoy_index.add_item(i, emb)\n",
    "        annoy_index.build(10)  # 10 trees\n",
    "        \n",
    "        # Search\n",
    "        return annoy_index.get_nns_by_vector(query_emb[0], top_k)\n",
    "    \n",
    "    def evaluate_all_approaches(self, output_file: str = \"results.json\"):\n",
    "        results = {}\n",
    "        search_approaches = {\n",
    "            'bm25': lambda q: self.bm25_search(q, 5),\n",
    "            'cosine': lambda q, m: self.cosine_search(q, m, 5),\n",
    "            'faiss_flat': lambda q, m: self.faiss_flat_search(q, m, 5),\n",
    "            'faiss_hnsw': lambda q, m: self.faiss_hnsw_search(q, m, 5),\n",
    "            'annoy': lambda q, m: self.annoy_search(q, m, 5)\n",
    "        }\n",
    "        \n",
    "        for model in self.models:\n",
    "            results[model] = {}\n",
    "            \n",
    "            for approach_name, search_func in search_approaches.items():\n",
    "                # Skip bm25 for non-embedding models\n",
    "                if approach_name == 'bm25' and model != 'bm25':\n",
    "                    continue\n",
    "                \n",
    "                print(f\"Evaluating {model} with {approach_name}...\")\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Get recommendations for all queries\n",
    "                recommended_items_list = []\n",
    "                for query in self.queries:\n",
    "                    if approach_name == 'bm25':\n",
    "                        recs = search_func(query)\n",
    "                    else:\n",
    "                        recs = search_func(query, model)\n",
    "                    recommended_items_list.append(recs)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                metrics = MetricsCalculator.calculate_all_metrics(\n",
    "                    self.relevant_items_list,\n",
    "                    recommended_items_list,\n",
    "                    k_values=[5]  # We only care about top 5\n",
    "                )\n",
    "                \n",
    "                # Record timing\n",
    "                elapsed = time.time() - start_time\n",
    "                metrics['time_per_query'] = elapsed / len(self.queries)\n",
    "                \n",
    "                results[model][approach_name] = metrics\n",
    "        \n",
    "        # Save results\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6cfac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    evaluator = SearchEvaluator(\"validation_set.json\")\n",
    "    results = evaluator.evaluate_all_approaches()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
